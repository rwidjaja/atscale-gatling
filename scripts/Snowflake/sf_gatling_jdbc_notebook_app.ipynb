{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "bxksvzczo7luwsgvb556",
   "authorId": "7749513225674",
   "authorName": "STEVE_HALL",
   "authorEmail": "steve.hall@atscale.com",
   "sessionId": "748a00aa-93ea-473e-a0f2-3f258f8e2102",
   "lastEditTime": 1763073823654
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "setup"
   },
   "source": "# Import python packages\nimport pandas as pd\nimport numpy as np\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n\nreport_data = {}\nsuccess = True\n\n#set the run_ids for the evaluation\nraw_runids = \"2025-11-13-DYA75F9xjI, 2025-11-13-YP0bpvPIXN\" \n\nrunids = [item.strip() for item in raw_runids.split(',')]\nrunid_a= runids[0]\nrunid_b= runids[1]\n\n#set the performance threshold for the evaluation\nperf_threshold_percent = 70\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "06052797-c35c-4f91-8b2f-0bd7db9e4cba",
   "metadata": {
    "language": "python",
    "name": "failed_queries",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "statement = f\"\"\"\nselect *\nfrom GATLING_SQL_HEADERS\nwhere status = 'FAILED'\nand gatling_run_id in ('{runid_a}','{runid_b}')\n\"\"\"\ndf = session.sql(statement).to_pandas()\nnum_rows = df.shape[0]\n\n\n\nif(num_rows == 0):\n    report_data['Failed queries'] = f\"{num_rows} queries report as failed for run ids : {runid_a} and {runid_b}\"\n    report_data['Failed queries']\nelse:\n    success = success and False\n    report_data['Failed queries'] = f\"{num_rows} queries report as failed for run ids : {runid_a} and {runid_b}\"\n    report_data['Failed queries']\n    df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d897a12f-74d7-414f-8db7-be2cf403e9f9",
   "metadata": {
    "language": "python",
    "name": "inconsistent_failure_check",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "statement = f\"\"\"\nSELECT\n    COALESCE(a.QUERY_HASH, b.QUERY_HASH) AS query_hash,\n    a.QUERY_NAME AS query_name_a,\n    a.STATUS AS status_a,\n    b.QUERY_NAME AS query_name_b,\n    b.STATUS AS status_b,\n    CASE\n        WHEN a.GATLING_RUN_ID IS NULL THEN 'Failed in B only (Query missing from A)'\n        WHEN b.GATLING_RUN_ID IS NULL THEN 'Failed in A only (Query missing from B)'\n        WHEN a.STATUS = 'FAILED' AND b.STATUS != 'FAILED' THEN 'Failed in A only'\n        WHEN a.STATUS != 'FAILED' AND b.STATUS = 'FAILED' THEN 'Failed in B only'\n        ELSE 'Status Mismatch'\n    END AS failure_type\nFROM\n    (SELECT * FROM GATLING_SQL_DETAILS WHERE GATLING_RUN_ID = '{runid_a}') a\nFULL OUTER JOIN\n    (SELECT * FROM GATLING_SQL_DETAILS WHERE GATLING_RUN_ID = '{runid_b}') b\nON\n    a.QUERY_HASH = b.QUERY_HASH\nWHERE\n    (a.STATUS IS DISTINCT FROM b.STATUS) -- Status is different (e.g., FAILED vs OK, or one is NULL)\n    OR (a.GATLING_RUN_ID IS NULL AND b.GATLING_RUN_ID IS NOT NULL) -- Query only exists in B\n    OR (b.GATLING_RUN_ID IS NULL AND a.GATLING_RUN_ID IS NOT NULL); -- Query only exists in A\n\"\"\"\n\ndf = session.sql(statement).to_pandas()\n\nnum_rows = df.shape[0]\n\nif (num_rows == 0):\n    report_data['Failed query details'] = f\"If query failures exist they are consistent between runs for run ids : {runid_a} and {runid_b}\"\n    report_data['Failed query details']\nelse:\n    success = success and False\n    report_data['Failed query details'] = f\"There are {num_rows} query failure differences between query runs for run ids : {runid_a} and {runid_b}\"\n    report_data['Failed query details']\n    df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b29c33b8-7969-48ec-acb1-c94e71ba5202",
   "metadata": {
    "language": "python",
    "name": "queries_by_model_validation",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "statement = f\"\"\"\nSelect gatling_run_id, model, count(query_name) as num_queries \nfrom gatling_archive.run_logs.gatling_sql_logs\nwhere gatling_run_id in ('{runid_a}', '{runid_b}')\ngroup by 1, 2\n\"\"\"\n\ndf = session.sql(statement).to_pandas()\n\nnum_rows = df.shape[0]\nassert num_rows == 2, f\"Expected 2 rows found {num_rows}\"\n\ncolumn_name = 'NUM_QUERIES'\n\n# Get the value from the first row to compare against\nexpected_value = df[column_name].iloc[0]\n\nare_all_same = (df[column_name] == expected_value).all()\n\nif(are_all_same):\n    report_data['Queries by model'] = f\"✅ Validated number of query result set rows by model: {expected_value}\"\n    report_data['Queries by model']\nelse:\n    success = success and False\n    report_data['Queries by model'] = f\"Result sets contain inconsistent number of rows.\"\n    report_data['Queries by model']\n    df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "225bc7b0-41b0-4e66-9c39-612c8f00637a",
   "metadata": {
    "language": "python",
    "name": "headers_by_model_validation",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "statement = f\"\"\"\nSelect gatling_run_id, model, count(query_name) as num_queries \nfrom gatling_sql_headers\nwhere gatling_run_id in ('{runid_a}', '{runid_b}')\ngroup by 1, 2\n\"\"\"\n\ndf = df = session.sql(statement).to_pandas()\n\nnum_rows = df.shape[0]\nassert num_rows == 2, f\"Expected 2 rows found {num_rows}\"\n\ncolumn_name = 'NUM_QUERIES'\n\n# Get the value from the first row to compare against\nexpected_value = df[column_name].iloc[0]\n\nare_all_same = (df[column_name] == expected_value).all()\n\nif(are_all_same):\n    report_data['Headers by model'] = f\"✅ Validated numer of headers by model: {expected_value}\"\n    report_data['Headers by model']\nelse:\n    success = success and False\n    report_data['Headers by model'] = f\"Column '{column_name}' contains inconsistent values.\"\n    report_data['Headers by model']\n    df\n\n    ",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "18dd1efa-1e9a-4636-ab12-d37c510584ab",
   "metadata": {
    "language": "python",
    "name": "details_by_model_validation",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "statement = f\"\"\"\nSelect gatling_run_id, model, count(query_name) as num_queries \nfrom gatling_sql_details\nwhere gatling_run_id in ('{runid_a}', '{runid_b}')\ngroup by 1, 2\n\"\"\"\ndf = session.sql(statement).to_pandas()\n\nnum_rows = df.shape[0]\nassert num_rows == 2, f\"Expected 2 rows found {num_rows}\"\n\ncolumn_name = 'NUM_QUERIES'\n\n# Get the value from the first row to compare against\nexpected_value = df[column_name].iloc[0]\n\nare_all_same = (df[column_name] == expected_value).all()\n\nif(are_all_same):\n    report_data['Details by model'] = f\"✅ Validated numer of detail records by model: {expected_value}\"\n    report_data['Details by model']\nelse:\n    success = success and False\n    report_data['Details by model'] = f\"Column '{column_name}' contains inconsistent values.\"\n    report_data['Details by model']\n    df\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c3d611dc-a332-409b-8e6c-7f11887b43e8",
   "metadata": {
    "language": "python",
    "name": "results_match_validatiion",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "results_matching_query = f\"\"\"\nwith\n    a as (\n        select\n            model as model_name,\n            query_name,\n            query_hash,\n            status,\n            gatling_session_id,\n            rownumber,\n            row_hash\n        from gatling_sql_details\n        where gatling_run_id = '{runid_a}'\n        order by model_name, query_name, query_hash, gatling_session_id, rownumber\n    ),\n    b as (\n        select\n            model as model_name,\n            query_name,\n            query_hash,\n            status,\n            gatling_session_id,\n            rownumber,\n            row_hash\n        from gatling_sql_details\n        where gatling_run_id = '{runid_b}'\n        order by model_name, query_name, query_hash, gatling_session_id, rownumber\n    )\nselect * from a where not exists (select row_hash from b where a.row_hash = b.row_hash)\n    UNION\n    select * from b where not exists (select row_hash from a where a.row_hash = b.row_hash)\n\"\"\"\n\ndf = session.sql(results_matching_query)\n\n# Get the row count\nrow_count = df.count()\n\nif(row_count == 0):\n    report_data['Results Matching Test'] = f\"✅ Validated results match for run ids : {runid_a} and {runid_b}\"\n    report_data['Results Matching Test']\nelse:\n    success = success and False\n    report_data['Results Matching Test'] = f\"Failed there are {row_count} records where results do not match as expected for run ids: {runid_a} and {runid_b}\"\n    report_data['Results Matching Test']\n    df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5b87390d-ad1c-449a-994e-57aa3eade7e9",
   "metadata": {
    "language": "python",
    "name": "performance_validation",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "performance_evaluation_query = f\"\"\"\nwith\n    a as (\n        select\n            run_key,\n            model as model_name,\n            query_name,\n            query_hash,\n            status,\n            concurrent_users,\n            header_duration_ms as duration_ms\n        from v_gatling_joined\n        where gatling_run_id = '{runid_a}'\n    qualify row_number() over (partition by test_name, model, query_hash, concurrent_users order by header_ts desc) = 1\n    ),\n    b as (\n        select\n            run_key,\n            model as model_name,\n            query_name,\n            query_hash,\n            status,\n            concurrent_users,\n            header_duration_ms as duration_ms\n        from v_gatling_joined\n        where gatling_run_id = '{runid_b}'\n    qualify row_number() over (partition by test_name, model, query_hash, concurrent_users order by header_ts desc) = 1\n    ),\n    joined as (\n        select\n            a.model_name,\n            a.query_name,\n            a.query_hash,\n            a.status,\n            a.concurrent_users,\n            a.duration_ms as duration_a,\n            b.duration_ms as duration_b,\n            round(((b.duration_ms - a.duration_ms) / nullif(a.duration_ms, 0)) * 100, 2) as pct_diff\n        from a\n            join b\n        on  a.model_name       = b.model_name\n            and a.query_hash       = b.query_hash\n    )\nselect\n    model_name,\n    query_name,\n    query_hash,\n    status,\n    concurrent_users,\n    duration_a,\n    duration_b,\n    pct_diff,\n    case\n        when pct_diff > 0 then 'SLOWER'\n        when pct_diff < 0 then 'FASTER'\n        else 'SAME'\n        end as perf_change\nfrom joined\nwhere abs(pct_diff) >= {perf_threshold_percent}\norder by abs(pct_diff) desc, query_hash\n\"\"\"\n\ndf = session.sql(performance_evaluation_query)\n\n# Get the row count\nrow_count = df.count()\n\nif(row_count == 0):\n    report_data['Performance Evaluation Test'] = f\"✅ Validated performance results for run ids: {runid_a} and {runid_b} are within {perf_threshold_percent} percent\"\n    report_data['Performance Evaluation Test']\nelse:\n    success = success and False\n    report_data['Performance Evaluation Test'] = f\"Failed performance results for for run ids: {runid_a} and {runid_b} {row_count} records are not within {perf_threshold_percent} percent as expected\"\n    report_data['Performance Evaluation Test']\n    df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "17126b3c-b411-4526-8b87-83173d532ee2",
   "metadata": {
    "language": "python",
    "name": "cell8",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "report_data",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8c39f37c-e10e-4730-a4af-11ad1026e602",
   "metadata": {
    "language": "python",
    "name": "cell1",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "if success:\n    assert(True)\n    print(\"All tests passed\")\nelse:\n    print(\"Check for test failures\")\n    assert(False)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "79abbd1b-499e-46d6-a72f-a65a7f5f6488",
   "metadata": {
    "language": "python",
    "name": "cell2",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "",
   "execution_count": null
  }
 ]
}