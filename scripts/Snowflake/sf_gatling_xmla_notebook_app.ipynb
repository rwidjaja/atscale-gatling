{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "yd6kbspvzcv3jmfpaprv",
   "authorId": "7749513225674",
   "authorName": "STEVE_HALL",
   "authorEmail": "steve.hall@atscale.com",
   "sessionId": "1276cd60-536b-44d0-849c-681c7ef45d0d",
   "lastEditTime": 1762791338853
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "setup"
   },
   "source": "# Import python packages\nimport pandas as pd\nimport numpy as np\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n\nreport_data = {}\nsuccess = True\n\n#set the run_ids for the evaluation\nraw_runids = \"2025-11-06-K5eXH6xcKy, 2025-11-06-tcVRt01cgL\" \n\nrunids = [item.strip() for item in raw_runids.split(',')]\nrunid_a= runids[0]\nrunid_b= runids[1]\n\n#set the performance threshold for the evaluation\nperf_threshold_percent = 70\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "python",
    "name": "failed_queries",
    "codeCollapsed": false
   },
   "source": "statement = f\"\"\"\nselect *\nfrom GATLING_XMLA_HEADERS\nwhere status = 'FAILED'\nand gatling_run_id in ('{runid_a}','{runid_b}')\n\"\"\"\ndf = session.sql(statement).to_pandas()\nnum_rows = df.shape[0]\n\nif(num_rows == 0):\n    report_data['Failed queries'] = f\"{num_rows} queries report as failed for run ids : {runid_a} and {runid_b}\"\n    report_data['Failed queries']\nelse:\n    success = success and False\n    report_data['Failed queries'] = f\"{num_rows} queries report as failed for run ids : {runid_a} and {runid_b}\"\n    report_data['Failed queries']\n    df",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "inconsistent_failure_check",
    "codeCollapsed": false
   },
   "source": "statement = f\"\"\"\nSELECT\n    COALESCE(a.QUERY_HASH, b.QUERY_HASH) AS query_hash,\n    a.QUERY_NAME AS query_name_a,\n    a.STATUS AS status_a,\n    b.QUERY_NAME AS query_name_b,\n    b.STATUS AS status_b,\n    CASE\n        WHEN a.GATLING_RUN_ID IS NULL THEN 'Failed in B only (Query missing from A)'\n        WHEN b.GATLING_RUN_ID IS NULL THEN 'Failed in A only (Query missing from B)'\n        WHEN a.STATUS = 'FAILED' AND b.STATUS != 'FAILED' THEN 'Failed in A only'\n        WHEN a.STATUS != 'FAILED' AND b.STATUS = 'FAILED' THEN 'Failed in B only'\n        ELSE 'Status Mismatch'\n    END AS failure_type\nFROM\n    (SELECT * FROM GATLING_XMLA_HEADERS WHERE GATLING_RUN_ID = '{runid_a}') a\nFULL OUTER JOIN\n    (SELECT * FROM GATLING_XMLA_HEADERS WHERE GATLING_RUN_ID = '{runid_b}') b\nON\n    a.QUERY_HASH = b.QUERY_HASH\nWHERE\n    (a.STATUS IS DISTINCT FROM b.STATUS) -- Status is different (e.g., FAILED vs OK, or one is NULL)\n    OR (a.GATLING_RUN_ID IS NULL AND b.GATLING_RUN_ID IS NOT NULL) -- Query only exists in B\n    OR (b.GATLING_RUN_ID IS NULL AND a.GATLING_RUN_ID IS NOT NULL); -- Query only exists in A\n\"\"\"\n\ndf = session.sql(statement).to_pandas()\n\nnum_rows = df.shape[0]\n\nif (num_rows == 0):\n    report_data['Failed query details'] = f\"If query failures exist they are consistent between runs for run ids : {runid_a} and {runid_b}\"\n    report_data['Failed query details']\nelse:\n    success = success and False\n    report_data['Failed query details'] = f\"There are {num_rows} query failure differences between query runs for run ids : {runid_a} and {runid_b}\"\n    report_data['Failed query details']\n    df",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c92db823-9644-4372-a401-c0ced267e5a9",
   "metadata": {
    "language": "python",
    "name": "queries_by_model_validation",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "statement = f\"\"\"\nSelect gatling_run_id, model, count(query_name) as num_queries \nfrom gatling_xmla_headers\nwhere gatling_run_id in ('{runid_a}', '{runid_b}')\ngroup by 1, 2\n\"\"\"\n\ndf = session.sql(statement).to_pandas()\n\nnum_rows = df.shape[0]\nassert num_rows == 2, f\"Expected 2 rows found {num_rows} Check the values set for runid_a and runid_b\"\n\ncolumn_name = 'NUM_QUERIES'\n\n# Get the value from the first row to compare against\nexpected_value = df[column_name].iloc[0]\n\nare_all_same = (df[column_name] == expected_value).all()\n\nif(are_all_same):\n    report_data['Queries by model'] = f\"✅ Validated number of query result set rows by model: {expected_value}\"\n    report_data['Queries by model']\nelse:\n    success = success and False\n    report_data['Queries by model'] = f\"Result sets contain inconsistent number of rows.\"\n    report_data['Queries by model']\n    df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "06bf2661-b0f2-442b-9002-397e310312ba",
   "metadata": {
    "language": "python",
    "name": "responses_by_model_validation",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "statement = f\"\"\"\nSelect gatling_run_id, model, count(query_name) as num_queries \nfrom gatling_xmla_responses\nwhere gatling_run_id in ('{runid_a}', '{runid_b}')\ngroup by 1, 2\n\"\"\"\ndf = session.sql(statement).to_pandas()\n\nnum_rows = df.shape[0]\nassert num_rows == 2, f\"Expected 2 rows found {num_rows}\"\n\ncolumn_name = 'NUM_QUERIES'\n\n# Get the value from the first row to compare against\nexpected_value = df[column_name].iloc[0]\n\nare_all_same = (df[column_name] == expected_value).all()\n\nif(are_all_same):\n    report_data['Details by model'] = f\"✅ Validated numer of detail records by model: {expected_value}\"\n    report_data['Details by model']\nelse:\n    success = success and False\n    report_data['Details by model'] = f\"Column '{column_name}' contains inconsistent values.\"\n    report_data['Details by model']\n    df\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "616ffd0c-6431-4562-97ee-a4d71aa0c1ed",
   "metadata": {
    "language": "python",
    "name": "results_match_validation",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "results_matching_query = f\"\"\"\nwith\n    a as (\n        select\n            model as model_name,\n            query_name,\n            query_hash,\n            status,\n            soap_body_hash\n        from gatling_xmla_responses\n        where gatling_run_id = '{runid_a}'\n    ),\n    b as (\n        select\n            model as model_name,\n            query_name,\n            query_hash,\n            status,\n            soap_body_hash\n        from gatling_xmla_responses\n        where gatling_run_id = '{runid_b}'\n    )\nselect\n    a.model_name,\n    a.query_name,\n    a.query_hash,\n    a.status,\n    a.soap_body_hash as soap_body_hash_a,\n    b.soap_body_hash as soap_body_hash_b\nfrom a\n         join b\n              on a.model_name           = b.model_name\n                and a.query_name        = b.query_name\n                and a.query_hash    = b.query_hash\nwhere a.soap_body_hash <> b.soap_body_hash\norder by a.query_name\n\"\"\"\n\ndf = session.sql(results_matching_query)\n\n# Get the row count\nrow_count = df.count()\n\nif(row_count == 0):\n    report_data['Results Matching Test'] = f\"✅ Validated results match for run ids : {runid_a} and {runid_b}\"\n    report_data['Results Matching Test']\nelse:\n    success = success and False\n    report_data['Results Matching Test'] = f\"Failed there are {row_count} records where results do not match as expected for run ids: {runid_a} and {runid_b}\"\n    report_data['Results Matching Test']\n    df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c0529a85-4888-4744-922a-e9e1b96e58d2",
   "metadata": {
    "language": "python",
    "name": "performance_validation",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "performance_evaluation_query = f\"\"\"\nwith\n    a as (\n        select\n            model as model_name,\n            query_name,\n            query_hash,\n            gatling_session_id,\n            status,\n            duration_ms\n        from gatling_xmla_headers\n        where gatling_run_id = '{runid_a}'\n    ),\n    b as (\n        select\n            model as model_name,\n            query_name,\n            query_hash,\n            gatling_session_id,\n            status,\n            duration_ms\n        from gatling_xmla_headers\n        where gatling_run_id = '{runid_b}'\n    ),\n    joined as (\n        select\n            a.model_name,\n            a.query_name,\n            a.query_hash,\n            a.gatling_session_id,\n            a.status,\n            a.duration_ms as duration_a,\n            b.duration_ms as duration_b,\n            round(((b.duration_ms - a.duration_ms) / nullif(a.duration_ms, 0)) * 100, 2) as pct_diff\n        from a\n            join b\n            on  a.model_name         = b.model_name\n            and a.query_hash         = b.query_hash\n            and a.gatling_session_id = b.gatling_session_id\n    )\n\nselect\n    model_name,\n    query_name,\n    query_hash,\n    gatling_session_id as simulation_user,\n    status,\n    duration_a,\n    duration_b,\n    pct_diff,\n    case\n        when pct_diff > 0 then 'SLOWER'\n        when pct_diff < 0 then 'FASTER'\n        else 'SAME'\n        end as perf_change\nfrom joined\nwhere abs(pct_diff) >= {perf_threshold_percent}\norder by abs(pct_diff) desc, query_hash\n\"\"\"\n\ndf = session.sql(performance_evaluation_query)\n\n# Get the row count\nrow_count = df.count()\n\nif(row_count == 0):\n    report_data['Performance Evaluation Test'] = f\"✅ Validated performance results for run ids: {runid_a} and {runid_b} are within {perf_threshold_percent} percent\"\n    report_data['Performance Evaluation Test']\nelse:\n    success = success and False\n    report_data['Performance Evaluation Test'] = f\"Failed performance results for for run ids: {runid_a} and {runid_b} {row_count} records are not within {perf_threshold_percent} percent as expected\"\n    report_data['Performance Evaluation Test']\n    df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "937e1a91-a95a-4692-b2b0-006ff539b4ea",
   "metadata": {
    "language": "python",
    "name": "cell1",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "report_data",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "70eaf9bf-8c80-418f-b286-1ff6a1a93753",
   "metadata": {
    "language": "python",
    "name": "cell3",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "if success:\n    assert(True)\n    print(\"All tests passed\")\nelse:\n    print(\"Check for test failures\")\n    assert(False)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "71fe69f3-bfe4-4fce-a544-8702c7c9e3bc",
   "metadata": {
    "language": "python",
    "name": "cell2",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "",
   "execution_count": null
  }
 ]
}